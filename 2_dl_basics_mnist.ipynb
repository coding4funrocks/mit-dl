{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.0\n"
     ]
    }
   ],
   "source": [
    "# TensorFlow and tf.keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense\n",
    "\n",
    "# Commonly used modules\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Images, plots, display, and visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "import IPython\n",
    "from six.moves import urllib\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set common constants\n",
    "this_repo_url = 'https://github.com/lexfridman/mit-deep-learning/raw/master/'\n",
    "this_tutorial_url = this_repo_url + 'tutorial_deep_learning_basics'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = keras.datasets.mnist.load_data()\n",
    "\n",
    "# reshape images to specify that it's a single channel\n",
    "train_images = train_images.reshape(train_images.shape[0], 28, 28, 1)\n",
    "test_images = test_images.reshape(test_images.shape[0], 28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_images(imgs):\n",
    "    sample_img = img if len(imgs.shape) == 2 else imgs[0]\n",
    "    assert sample_img.shape in [(28, 28, 1), (28, 28)], sample_img.shape\n",
    "    return imgs / 255.0\n",
    "\n",
    "train_images = preprocess_images(train_images)\n",
    "test_images = preprocess_images(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x144 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 2))\n",
    "for i in range(5):\n",
    "    plt.subplot(1, 5, i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(train_images[i].reshape(28, 28), cmap = plt.cm.binary)\n",
    "    plt.xlabel(train_labels[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model\n",
    "model = keras.Sequential()\n",
    "model.add(Conv2D(32, kernel_size = (3, 3), activation = 'relu', input_shape = (28, 28, 1)))\n",
    "model.add(Conv2D(64, (3, 3), activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation = 'relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = tf.train.AdamOptimizer(),\n",
    "             loss = 'sparse_categorical_crossentropy',\n",
    "             metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 376s 6ms/step - loss: 0.1982 - acc: 0.9402\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 330s 5ms/step - loss: 0.0811 - acc: 0.9756\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 244s 4ms/step - loss: 0.0612 - acc: 0.9814\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 237s 4ms/step - loss: 0.0506 - acc: 0.9846\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 228s 4ms/step - loss: 0.0449 - acc: 0.9862\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(train_images, train_labels, epochs = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 28, 28, 1)\n",
      "10000/10000 [==============================] - 12s 1ms/step\n",
      "Test accuracy: 0.9893\n"
     ]
    }
   ],
   "source": [
    "# Evaluate accuracy\n",
    "print(test_images.shape)\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading the sample video...\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "(720, 720, 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-d7f9fc2192bf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[0mimg_proc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[0mimg_proc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_proc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m28\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m28\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m     \u001b[0mimg_proc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreprocess_images\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_proc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m     \u001b[0mimg_proc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mimg_proc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-214e9e86d271>\u001b[0m in \u001b[0;36mpreprocess_images\u001b[1;34m(imgs)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mpreprocess_images\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0msample_img\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimg\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mimgs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[1;32massert\u001b[0m \u001b[0msample_img\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m28\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m28\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m28\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m28\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_img\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mimgs\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m255.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: (720, 720, 3)"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "mnist_dream_path = 'images/mnist_dream.mp4'\n",
    "mnist_prediction_path = 'images/mnist_dream_predicted.mp4'\n",
    "\n",
    "# download the video if running in Colab\n",
    "if not os.path.isfile(mnist_dream_path): \n",
    "    print('downloading the sample video...')\n",
    "    vid_url = this_tutorial_url + '/' + mnist_dream_path\n",
    "    \n",
    "    mnist_dream_path = urllib.request.urlretrieve(vid_url)[0]\n",
    "                                                                                                  \n",
    "def cv2_imshow(img):\n",
    "    ret = cv2.imencode('.png', img)[1].tobytes() \n",
    "    img_ip = IPython.display.Image(data=ret)\n",
    "    IPython.display.display(img_ip)\n",
    "\n",
    "cap = cv2.VideoCapture(mnist_dream_path) \n",
    "vw = None\n",
    "frame = -1 # counter for debugging (mostly), 0-indexed\n",
    "\n",
    "# go through all the frames and run our classifier on the high res MNIST images as they morph from number to number\n",
    "while True:\n",
    "    frame += 1\n",
    "    ret, img = cap.read()\n",
    "    if not ret: break\n",
    "               \n",
    "    assert img.shape[0] == img.shape[1]\n",
    "    if img.shape[0] != 720:\n",
    "        img = cv2.resize(img, (720, 720))\n",
    "       \n",
    "    #preprocess the image for prediction\n",
    "    img_proc = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    img_proc = cv2.resize(img_proc, (28, 28))\n",
    "    img_proc = preprocess_images(img_proc)\n",
    "    img_proc = 1 - img_proc\n",
    "\n",
    "    net_in = np.expand_dims(img_proc, axis=0)\n",
    "    net_in = np.expand_dims(net_in, axis=3)\n",
    "    \n",
    "    preds = model.predict(net_in)[0]\n",
    "    guess = np.argmax(preds)\n",
    "    perc = np.rint(preds * 100).astype(int)\n",
    "    \n",
    "    img = 255 - img\n",
    "    pad_color = 0\n",
    "    img = np.pad(img, ((0,0), (0,1280-720), (0,0)), mode='constant', constant_values=(pad_color))  \n",
    "    \n",
    "    line_type = cv2.LINE_AA\n",
    "    font_face = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    font_scale = 1.3        \n",
    "    thickness = 2\n",
    "    x, y = 740, 60\n",
    "    color = (255, 255, 255)\n",
    "    \n",
    "    text = \"Neural Network Output:\"\n",
    "    cv2.putText(img, text=text, org=(x, y), fontScale=font_scale, fontFace=font_face, thickness=thickness,\n",
    "                    color=color, lineType=line_type)\n",
    "    \n",
    "    text = \"Input:\"\n",
    "    cv2.putText(img, text=text, org=(30, y), fontScale=font_scale, fontFace=font_face, thickness=thickness,\n",
    "                    color=color, lineType=line_type)   \n",
    "        \n",
    "    y = 130\n",
    "    for i, p in enumerate(perc):\n",
    "        if i == guess: color = (255, 218, 158)\n",
    "        else: color = (100, 100, 100)\n",
    "            \n",
    "        rect_width = 0\n",
    "        if p > 0: rect_width = int(p * 3.3)\n",
    "        \n",
    "        rect_start = 180\n",
    "        cv2.rectangle(img, (x+rect_start, y-5), (x+rect_start+rect_width, y-20), color, -1)\n",
    "\n",
    "        text = '{}: {:>3}%'.format(i, int(p))\n",
    "        cv2.putText(img, text=text, org=(x, y), fontScale=font_scale, fontFace=font_face, thickness=thickness,\n",
    "                    color=color, lineType=line_type)\n",
    "        y += 60\n",
    "    \n",
    "    # if you don't want to save the output as a video, set this to False\n",
    "    save_video = True\n",
    "    \n",
    "    if save_video:\n",
    "        if vw is None:\n",
    "            codec = cv2.VideoWriter_fourcc(*'DIVX')\n",
    "            vid_width_height = img.shape[1], img.shape[0]\n",
    "            vw = cv2.VideoWriter(mnist_prediction_path, codec, 30, vid_width_height)\n",
    "        vw.write(img)\n",
    "        vw.write(img)\n",
    "    \n",
    "    # scale down image for display\n",
    "    img_disp = cv2.resize(img, (0,0), fx=0.5, fy=0.5)\n",
    "    cv2_imshow(img_disp)\n",
    "    IPython.display.clear_output(wait=True)\n",
    "        \n",
    "cap.release()\n",
    "if vw is not None:\n",
    "    vw.release()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
